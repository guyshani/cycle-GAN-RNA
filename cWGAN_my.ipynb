{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import wandb\n",
    "import h5py\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, x_dim, vocab_sizes, nb_numeric, h_dims, z_dim):\n",
    "        \"\"\"\n",
    "        Generator network for conditional GAN\n",
    "        Args:\n",
    "            x_dim: Dimension of output data\n",
    "            vocab_sizes: List of vocabulary sizes for each categorical variable\n",
    "            nb_numeric: Number of numeric covariates\n",
    "            h_dims: List of hidden dimensions\n",
    "            z_dim: Dimension of latent noise vector\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Embedding layers for categorical variables\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(vocab_size, min(50, vocab_size)) \n",
    "            for vocab_size in vocab_sizes\n",
    "        ])\n",
    "        \n",
    "        # Calculate total embedding dimension\n",
    "        embedding_dim = sum(min(50, vocab_size) for vocab_size in vocab_sizes)\n",
    "        \n",
    "        # Input dimension is latent dim + embedding dim + numeric covariates\n",
    "        input_dim = z_dim + embedding_dim + nb_numeric\n",
    "        \n",
    "        # Build generator network\n",
    "        layers = []\n",
    "        current_dim = input_dim\n",
    "        \n",
    "        # Add hidden layers\n",
    "        for h_dim in h_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(current_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "            current_dim = h_dim\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(current_dim, x_dim))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z, cat_covs, num_covs):\n",
    "        # Process categorical covariates through embeddings\n",
    "        embeddings = [emb(cat_covs[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        embedded = torch.cat(embeddings, dim=1)\n",
    "        \n",
    "        # Concatenate all inputs\n",
    "        gen_input = torch.cat([z, embedded, num_covs], dim=1)\n",
    "        \n",
    "        # Generate output\n",
    "        return self.network(gen_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, x_dim, vocab_sizes, nb_numeric, h_dims):\n",
    "        \"\"\"\n",
    "        Discriminator network for conditional GAN\n",
    "        Args:\n",
    "            x_dim: Dimension of input data\n",
    "            vocab_sizes: List of vocabulary sizes for each categorical variable\n",
    "            nb_numeric: Number of numeric covariates\n",
    "            h_dims: List of hidden dimensions\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Embedding layers for categorical variables\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(vocab_size, min(50, vocab_size))\n",
    "            for vocab_size in vocab_sizes\n",
    "        ])\n",
    "        \n",
    "        # Calculate total embedding dimension\n",
    "        embedding_dim = sum(min(50, vocab_size) for vocab_size in vocab_sizes)\n",
    "        \n",
    "        # Input dimension is data dim + embedding dim + numeric covariates\n",
    "        input_dim = x_dim + embedding_dim + nb_numeric\n",
    "        \n",
    "        # Build discriminator network\n",
    "        layers = []\n",
    "        current_dim = input_dim\n",
    "        \n",
    "        # Add hidden layers\n",
    "        for h_dim in h_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(current_dim, h_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Dropout(0.3)\n",
    "            ])\n",
    "            current_dim = h_dim\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(current_dim, 1))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, cat_covs, num_covs):\n",
    "        # Process categorical covariates through embeddings\n",
    "        embeddings = [emb(cat_covs[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        embedded = torch.cat(embeddings, dim=1)\n",
    "        \n",
    "        # Concatenate all inputs\n",
    "        disc_input = torch.cat([x, embedded, num_covs], dim=1)\n",
    "        \n",
    "        # Generate output\n",
    "        return self.network(disc_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, dataloader, cat_covs, num_covs, \n",
    "              config, device, score_fn=None, save_fn=None):\n",
    "    \"\"\"\n",
    "    Train the conditional GAN with progress tracking and proper device handling\n",
    "    \"\"\"\n",
    "    # Optimizers\n",
    "    g_optimizer = optim.RMSprop(generator.parameters(), lr=config['lr'])\n",
    "    d_optimizer = optim.RMSprop(discriminator.parameters(), lr=config['lr'])\n",
    "    \n",
    "    # Convert covariates to tensors and move to device\n",
    "    cat_covs = torch.tensor(cat_covs, dtype=torch.long).to(device)\n",
    "    num_covs = torch.tensor(num_covs, dtype=torch.float32).to(device)\n",
    "    \n",
    "    total_batches = len(dataloader)\n",
    "    \n",
    "    print(f\"Starting training for {config['epochs']} epochs...\")\n",
    "    print(f\"Total batches per epoch: {total_batches}\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "        print(f\"\\nEpoch [{epoch+1}/{config['epochs']}]\")\n",
    "        \n",
    "        for batch_idx, (real_data,) in enumerate(dataloader):\n",
    "            batch_size = real_data.size(0)\n",
    "            \n",
    "            # Move real data to device\n",
    "            real_data = real_data.to(device)\n",
    "            \n",
    "            # Get random batch of categorical and numerical covariates\n",
    "            batch_indices = torch.randint(0, cat_covs.size(0), (batch_size,))\n",
    "            batch_cat_covs = cat_covs[batch_indices]\n",
    "            batch_num_covs = num_covs[batch_indices]\n",
    "            \n",
    "            # Train Discriminator\n",
    "            for _ in range(config['nb_critic']):\n",
    "                d_optimizer.zero_grad()\n",
    "                \n",
    "                # Generate fake data\n",
    "                z = torch.randn(batch_size, config['latent_dim']).to(device)\n",
    "                fake_data = generator(z, batch_cat_covs, batch_num_covs)\n",
    "                \n",
    "                # Calculate discriminator loss\n",
    "                real_validity = discriminator(real_data, batch_cat_covs, batch_num_covs)\n",
    "                fake_validity = discriminator(fake_data.detach(), batch_cat_covs, batch_num_covs)\n",
    "                \n",
    "                d_loss = -(torch.mean(real_validity) - torch.mean(fake_validity))\n",
    "                d_loss.backward()\n",
    "                d_optimizer.step()\n",
    "                \n",
    "                # Clip discriminator weights (Wasserstein GAN)\n",
    "                for p in discriminator.parameters():\n",
    "                    p.data.clamp_(-0.01, 0.01)\n",
    "                    \n",
    "                d_losses.append(d_loss.item())\n",
    "            \n",
    "            # Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            # Generate fake data\n",
    "            z = torch.randn(batch_size, config['latent_dim']).to(device)\n",
    "            fake_data = generator(z, batch_cat_covs, batch_num_covs)\n",
    "            \n",
    "            # Calculate generator loss\n",
    "            fake_validity = discriminator(fake_data, batch_cat_covs, batch_num_covs)\n",
    "            g_loss = -torch.mean(fake_validity)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            g_losses.append(g_loss.item())\n",
    "            \n",
    "            # Print progress every 10 batches\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"  Batch [{batch_idx}/{total_batches}] \" \\\n",
    "                      f\"D_loss: {d_loss.item():.4f}, \" \\\n",
    "                      f\"G_loss: {g_loss.item():.4f}\")\n",
    "        \n",
    "        # Print epoch summary\n",
    "        avg_d_loss = np.mean(d_losses)\n",
    "        avg_g_loss = np.mean(g_losses)\n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"  Average D_loss: {avg_d_loss:.4f}\")\n",
    "        print(f\"  Average G_loss: {avg_g_loss:.4f}\")\n",
    "        \n",
    "        # Log metrics\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\n",
    "                'epoch': epoch,\n",
    "                'd_loss': np.mean(d_losses),\n",
    "                'g_loss': np.mean(g_losses)\n",
    "            })\n",
    "        \n",
    "        # Evaluate and save model if needed\n",
    "        if score_fn is not None and epoch % 10 == 0:\n",
    "            score = score_fn(generator)\n",
    "            print(f'Epoch {epoch}: Score = {score:.4f}')\n",
    "        \n",
    "        if save_fn is not None and epoch % 50 == 0:\n",
    "            save_fn(generator, discriminator, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Categorical data shape: (41588, 3)\n",
      "Available categorical variables: ['dataset', 'cluster']\n",
      "\n",
      "Using categorical variables: ['dataset']\n",
      "\n",
      "Processing categorical variable: dataset\n",
      "Categories in dataset: ['dataset1' 'dataset2' 'dataset3' 'dataset4' 'dataset5' 'dataset6'\n",
      " 'dataset7']\n",
      "Number of categories: 7\n",
      "\n",
      "Combined categorical covariates shape: (41588, 1)\n",
      "\n",
      "Vocabulary sizes for categorical variables: [7]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 191\u001b[0m\n\u001b[1;32m    176\u001b[0m     train_gan(\n\u001b[1;32m    177\u001b[0m         generator\u001b[38;5;241m=\u001b[39mgenerator,\n\u001b[1;32m    178\u001b[0m         discriminator\u001b[38;5;241m=\u001b[39mdiscriminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;66;03m#save_fn=None\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;66;03m# Use specific categories:\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_categories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# Or use all available categories:\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# main()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 165\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(selected_categories)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Initialize wandb with unique run name\u001b[39;00m\n\u001b[1;32m    164\u001b[0m run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Uses timestamp for unique name\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madversarial_gene_expr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreinit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensures new run each time\u001b[39;49;00m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Add selected categories to wandb config\u001b[39;00m\n\u001b[1;32m    173\u001b[0m wandb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected_categories\u001b[39m\u001b[38;5;124m'\u001b[39m: categories_to_use})\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1289\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     wi \u001b[38;5;241m=\u001b[39m _WandbInit()\n\u001b[1;32m   1281\u001b[0m     wi\u001b[38;5;241m.\u001b[39msetup(\n\u001b[1;32m   1282\u001b[0m         init_settings\u001b[38;5;241m=\u001b[39minit_settings,\n\u001b[1;32m   1283\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         monitor_gym\u001b[38;5;241m=\u001b[39mmonitor_gym,\n\u001b[1;32m   1288\u001b[0m     )\n\u001b[0;32m-> 1289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:667\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    665\u001b[0m     latest_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl\u001b[38;5;241m.\u001b[39m_global_run_stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    666\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound existing run on stack: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatest_run\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 667\u001b[0m     \u001b[43mlatest_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetpid() \u001b[38;5;241m==\u001b[39m wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39m_init_pid:\n\u001b[1;32m    669\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb.init() called when a run is still active\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:442\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermwarn(message, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mDummy()\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:384\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2134\u001b[0m, in \u001b[0;36mRun.finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quiet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2127\u001b[0m     deprecate\u001b[38;5;241m.\u001b[39mdeprecate(\n\u001b[1;32m   2128\u001b[0m         field_name\u001b[38;5;241m=\u001b[39mdeprecate\u001b[38;5;241m.\u001b[39mDeprecated\u001b[38;5;241m.\u001b[39mrun__finish_quiet,\n\u001b[1;32m   2129\u001b[0m         warning_message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2132\u001b[0m         ),\n\u001b[1;32m   2133\u001b[0m     )\n\u001b[0;32m-> 2134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2164\u001b[0m, in \u001b[0;36mRun._finish\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_atexit_cleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2166\u001b[0m     \u001b[38;5;66;03m# Run hooks that should happen after the last messages to the\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m     \u001b[38;5;66;03m# internal service, like detaching the logger.\u001b[39;00m\n\u001b[1;32m   2168\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown_hooks:\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2392\u001b[0m, in \u001b[0;36mRun._atexit_cleanup\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2389\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39mresume_fname)\n\u001b[1;32m   2391\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2392\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mwandb_agent\u001b[38;5;241m.\u001b[39m_is_running():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2644\u001b[0m, in \u001b[0;36mRun._on_finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2637\u001b[0m exit_handle\u001b[38;5;241m.\u001b[39madd_probe(on_probe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_probe_exit)\n\u001b[1;32m   2639\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m progress\u001b[38;5;241m.\u001b[39mprogress_printer(\n\u001b[1;32m   2640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer,\n\u001b[1;32m   2641\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings,\n\u001b[1;32m   2642\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m progress_printer:\n\u001b[1;32m   2643\u001b[0m     \u001b[38;5;66;03m# Wait for the run to complete.\u001b[39;00m\n\u001b[0;32m-> 2644\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mexit_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2647\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_progress_exit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2648\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_printer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2649\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[38;5;66;03m# Print some final statistics.\u001b[39;00m\n\u001b[1;32m   2653\u001b[0m poll_exit_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mdeliver_poll_exit()\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py:279\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interface\u001b[38;5;241m.\u001b[39m_transport_keepalive_failed():\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 279\u001b[0m found, abandoned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_and_clear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# Always update progress to 100% when done\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_progress \u001b[38;5;129;01mand\u001b[39;00m progress_handle \u001b[38;5;129;01mand\u001b[39;00m progress_sent:\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py:126\u001b[0m, in \u001b[0;36m_MailboxSlot._get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_and_clear\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[pb\u001b[38;5;241m.\u001b[39mResult], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m    125\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    128\u001b[0m             found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/Documents/PHD/Aim_2/cycle_GAN/.venv/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py:122\u001b[0m, in \u001b[0;36m_MailboxSlot._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(selected_categories=None):\n",
    "    \"\"\"\n",
    "    Train the GAN with selected categorical variables\n",
    "    Args:\n",
    "        selected_categories: List of column names to use as categorical variables.\n",
    "                           If None, uses all columns except 'cell_id'\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    CONFIG = {\n",
    "        'epochs': 200,\n",
    "        'latent_dim': 64,\n",
    "        'batch_size': 32,\n",
    "        'nb_layers': 2,\n",
    "        'hdim': 256,\n",
    "        'lr': 5e-4,\n",
    "        'nb_critic': 5\n",
    "    }\n",
    "    \n",
    "    # Device configuration\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    data_path = \"/Users/guyshani/Documents/PHD/Aim_2/10x_data_mouse/\"\n",
    "    \n",
    "    # Load expression matrix\n",
    "    with h5py.File(data_path+'combined_scaled_data.h5', 'r') as f:\n",
    "        x_train = f['matrix'][:].T\n",
    "    \n",
    "    # Load all categorical variables from single file\n",
    "    cat_data = pd.read_csv(data_path+'combined_metadata.csv', sep=';')\n",
    "    print(\"Categorical data shape:\", cat_data.shape)\n",
    "    print(\"Available categorical variables:\", [col for col in cat_data.columns if col != 'cell_id'])\n",
    "    \n",
    "    # Determine which categories to use\n",
    "    if selected_categories is None:\n",
    "        # Use all columns except cell_id\n",
    "        categories_to_use = [col for col in cat_data.columns if col != 'cell_id']\n",
    "    else:\n",
    "        # Validate selected categories\n",
    "        invalid_categories = [cat for cat in selected_categories if cat not in cat_data.columns]\n",
    "        if invalid_categories:\n",
    "            raise ValueError(f\"Invalid categories: {invalid_categories}\")\n",
    "        categories_to_use = selected_categories\n",
    "    \n",
    "    print(f\"\\nUsing categorical variables: {categories_to_use}\")\n",
    "    \n",
    "    # Create dictionaries and inverse mappings for categorical variables\n",
    "    cat_dicts = []\n",
    "    encoded_covs = []\n",
    "    \n",
    "    # Process each selected column as a categorical variable\n",
    "    for column in categories_to_use:\n",
    "        # Get the column data\n",
    "        cat_vec = cat_data[column]\n",
    "        print(f\"\\nProcessing categorical variable: {column}\")\n",
    "        \n",
    "        # Create list of unique category names, sorted\n",
    "        dict_inv = np.array(list(sorted(set(cat_vec.values))))\n",
    "        dict_map = {t: i for i, t in enumerate(dict_inv)}\n",
    "        cat_dicts.append(dict_inv)\n",
    "        \n",
    "        # Convert categorical variables to integers\n",
    "        encoded = np.vectorize(lambda t: dict_map[t])(cat_vec)\n",
    "        encoded = encoded.reshape(-1, 1)  # Reshape to column vector\n",
    "        encoded_covs.append(encoded)\n",
    "        \n",
    "        print(f\"Categories in {column}:\", dict_inv)\n",
    "        print(f\"Number of categories:\", len(dict_inv))\n",
    "    \n",
    "    # Combine all categorical covariates\n",
    "    cat_covs = np.hstack(encoded_covs)\n",
    "    print(\"\\nCombined categorical covariates shape:\", cat_covs.shape)\n",
    "    \n",
    "    # Load numerical covariates (currently empty)\n",
    "    num_covs = np.zeros((x_train.shape[0], 0))\n",
    "    \n",
    "    # Convert data to PyTorch tensors and move to device\n",
    "    x_train = torch.tensor(x_train, dtype=torch.float32)  # Keep on CPU for DataLoader\n",
    "    \n",
    "    # Create data loader\n",
    "    train_dataset = TensorDataset(x_train)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    # Initialize models\n",
    "    vocab_sizes = [len(c) for c in cat_dicts]\n",
    "    print(\"\\nVocabulary sizes for categorical variables:\", vocab_sizes)\n",
    "    nb_numeric = num_covs.shape[-1]\n",
    "    x_dim = x_train.shape[-1]\n",
    "    ##\n",
    "    #print(\"x_train: \"+str(x_train))\n",
    "    #print(\"x_dim: \"+str(x_dim))\n",
    "    #print(\"vocab_sizes: \"+str(vocab_sizes))\n",
    "    \n",
    "    generator = Generator(\n",
    "        x_dim=x_dim,\n",
    "        vocab_sizes=vocab_sizes,\n",
    "        nb_numeric=nb_numeric,\n",
    "        h_dims=[CONFIG['hdim']] * CONFIG['nb_layers'],\n",
    "        z_dim=CONFIG['latent_dim']\n",
    "    ).to(device)\n",
    "    \n",
    "    discriminator = Discriminator(\n",
    "        x_dim=x_dim,\n",
    "        vocab_sizes=vocab_sizes,\n",
    "        nb_numeric=nb_numeric,\n",
    "        h_dims=[CONFIG['hdim']] * CONFIG['nb_layers']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Define save function\n",
    "    def save_models(generator, discriminator, epoch):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        # create save directory\n",
    "        categories_str = \"+\".join(categories_to_use)\n",
    "        save_dir = os.path.join(data_path, \"saved_models\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        # Create run folder\n",
    "        run_dir = os.path.join(save_dir, f\"run_{timestamp}_{categories_str}\")\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "        # Save model initialization parameters\n",
    "        model_config = {\n",
    "            'x_dim': x_dim,\n",
    "            'vocab_sizes': vocab_sizes,\n",
    "            'nb_numeric': nb_numeric,\n",
    "            'h_dims': [CONFIG['hdim']] * CONFIG['nb_layers'],\n",
    "            'z_dim': CONFIG['latent_dim'],\n",
    "            'categories': categories_to_use,\n",
    "            'training_config': CONFIG}\n",
    "        config_path = os.path.join(run_dir, 'model_config.json')\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(model_config, f, indent=4)\n",
    "        \n",
    "        # Save generator\n",
    "        generator_path = os.path.join(run_dir, f\"generator_{timestamp}_{categories_str}.pt\")\n",
    "        torch.save(generator.state_dict(), generator_path)\n",
    "        \n",
    "        \n",
    "        # Save discriminator\n",
    "        discriminator_path = os.path.join(run_dir, f\"discriminator_{timestamp}_{categories_str}.pt\")\n",
    "        torch.save(discriminator.state_dict(), discriminator_path)\n",
    "        \n",
    "        print(f\"\\nModels saved at epoch {epoch + 1}:\")\n",
    "        print(f\"Generator: {generator_path}\")\n",
    "        print(f\"Discriminator: {discriminator_path}\")\n",
    "        \n",
    "        # Log to wandb\n",
    "        if wandb.run is not None:\n",
    "            wandb.save(generator_path)\n",
    "            wandb.save(discriminator_path)\n",
    "\n",
    "    # Initialize wandb with unique run name\n",
    "    run_name = f\"run_{int(time.time())}\"  # Uses timestamp for unique name\n",
    "    wandb.init(\n",
    "        project='adversarial_gene_expr',\n",
    "        config=CONFIG,\n",
    "        name=run_name,\n",
    "        reinit=True  # Ensures new run each time\n",
    "    )\n",
    "    \n",
    "    # Add selected categories to wandb config\n",
    "    wandb.config.update({'selected_categories': categories_to_use})\n",
    "    \n",
    "    # Train model\n",
    "    train_gan(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        dataloader=train_loader,\n",
    "        cat_covs=cat_covs,\n",
    "        num_covs=num_covs,\n",
    "        config=CONFIG,\n",
    "        device=device,\n",
    "        save_fn=save_models\n",
    "        #save_fn=None\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example usage:\n",
    "    # Use specific categories:\n",
    "    main(selected_categories=['dataset'])\n",
    "    \n",
    "    # Or use all available categories:\n",
    "    # main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for data gneration\n",
    "def inspect_generator_dims(generator):\n",
    "    \"\"\"\n",
    "    Inspect the generator's dimensions and architecture\n",
    "    \n",
    "    Parameters:\n",
    "        generator: Generator model\n",
    "    \n",
    "    Returns:\n",
    "        dict containing dimension information\n",
    "    \"\"\"\n",
    "    # Get embedding dimensions\n",
    "    embedding_dims = [emb.embedding_dim for emb in generator.embeddings]\n",
    "    total_embedding_dim = sum(embedding_dims)\n",
    "    \n",
    "    # Get first layer dimension\n",
    "    first_layer_in_dim = generator.network[0].in_features\n",
    "    \n",
    "    return {\n",
    "        'embedding_dims': embedding_dims,\n",
    "        'total_embedding_dim': total_embedding_dim,\n",
    "        'first_layer_in_dim': first_layer_in_dim,\n",
    "        'recommended_latent_dim': first_layer_in_dim - total_embedding_dim\n",
    "    }\n",
    "\n",
    "def generate_expression_profiles(generator, n_samples, dataset_category, device='mps', debug=False):\n",
    "    \"\"\"\n",
    "    Generate gene expression profiles using the trained cWGAN generator\n",
    "    \n",
    "    Parameters:\n",
    "        generator: Trained Generator model\n",
    "        n_samples: Number of profiles to generate\n",
    "        dataset_category: Integer indicating which dataset category to generate (0-6 for dataset1-dataset7)\n",
    "        device: Device to run generation on ('cuda', 'mps', or 'cpu')\n",
    "        debug: If True, print debugging information\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of generated expression profiles with shape (n_samples, n_genes)\n",
    "    \"\"\"\n",
    "    # Set generator to eval mode\n",
    "    generator.eval()\n",
    "    \n",
    "    # Inspect dimensions\n",
    "    dims = inspect_generator_dims(generator)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Generator dimensions:\")\n",
    "        for k, v in dims.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    \n",
    "    # Create latent vectors\n",
    "    latent_dim = dims['recommended_latent_dim']\n",
    "    z = torch.randn(n_samples, latent_dim, device=device)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"\\nLatent vector shape: {z.shape}\")\n",
    "    \n",
    "    # Create categorical condition tensor\n",
    "    cat_covs = torch.full((n_samples, 1), dataset_category, dtype=torch.long, device=device)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Categorical covariates shape: {cat_covs.shape}\")\n",
    "    \n",
    "    # Create empty numeric covariates tensor\n",
    "    num_covs = torch.zeros((n_samples, 0), device=device)\n",
    "    \n",
    "    # Generate samples\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            # Get embeddings\n",
    "            embeddings = [emb(cat_covs[:, i]) for i, emb in enumerate(generator.embeddings)]\n",
    "            embedded = torch.cat(embeddings, dim=1)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"Embedded shape: {embedded.shape}\")\n",
    "            \n",
    "            # Concatenate inputs\n",
    "            gen_input = torch.cat([z, embedded, num_covs], dim=1)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"Generator input shape: {gen_input.shape}\")\n",
    "                print(f\"First layer input dim: {generator.network[0].in_features}\")\n",
    "                print(f\"First layer weight shape: {generator.network[0].weight.shape}\")\n",
    "            \n",
    "            # Generate samples\n",
    "            fake_samples = generator.network(gen_input)\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        print(\"\\nError during generation:\")\n",
    "        print(e)\n",
    "        print(\"\\nGenerator architecture:\")\n",
    "        print(generator)\n",
    "        raise\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    return fake_samples.cpu().numpy()\n",
    "\n",
    "def generate_and_save_profiles(generator, n_samples_per_category, save_path, device='mps', debug=False):\n",
    "    \"\"\"\n",
    "    Generate expression profiles for all dataset categories and save to file\n",
    "    \n",
    "    Parameters:\n",
    "        generator: Trained Generator model\n",
    "        n_samples_per_category: Number of samples to generate per dataset category\n",
    "        save_path: Path to save the generated profiles\n",
    "        device: Device to run generation on ('cuda', 'mps', or 'cpu')\n",
    "        debug: If True, print debugging information\n",
    "    \"\"\"\n",
    "    all_samples = []\n",
    "    all_categories = []\n",
    "    \n",
    "    # Generate samples for each dataset category\n",
    "    for category in range(7):  # 7 datasets (dataset1-dataset7)\n",
    "        if debug:\n",
    "            print(f\"\\nGenerating samples for dataset{category+1}\")\n",
    "        \n",
    "        samples = generate_expression_profiles(\n",
    "            generator, \n",
    "            n_samples_per_category, \n",
    "            category, \n",
    "            device,\n",
    "            debug=debug\n",
    "        )\n",
    "        all_samples.append(samples)\n",
    "        all_categories.extend([f'dataset{category+1}'] * n_samples_per_category)\n",
    "    # Print saved data path\n",
    "    print(\"Save location: \"+str(save_path))\n",
    "\n",
    "    # Combine all samples\n",
    "    all_samples = np.vstack(all_samples)\n",
    "    \n",
    "    # Save generated profiles\n",
    "    np.save(f'{save_path}_profiles.npy', all_samples)\n",
    "    \n",
    "    # Save category labels\n",
    "    with open(f'{save_path}_categories.txt', 'w') as f:\n",
    "        for category in all_categories:\n",
    "            f.write(f'{category}\\n')\n",
    "            \n",
    "    return all_samples, all_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "Generating samples for dataset1\n",
      "Generator dimensions:\n",
      "embedding_dims: [7]\n",
      "total_embedding_dim: 7\n",
      "first_layer_in_dim: 71\n",
      "recommended_latent_dim: 64\n",
      "\n",
      "Latent vector shape: torch.Size([100, 64])\n",
      "Categorical covariates shape: torch.Size([100, 1])\n",
      "Embedded shape: torch.Size([100, 7])\n",
      "Generator input shape: torch.Size([100, 71])\n",
      "First layer input dim: 71\n",
      "First layer weight shape: torch.Size([256, 71])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g_/c_f20pc566n31j9p36lcdc0w0000gn/T/ipykernel_19458/2294553458.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  generator.load_state_dict(torch.load(generator_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating samples for dataset2\n",
      "Generator dimensions:\n",
      "embedding_dims: [7]\n",
      "total_embedding_dim: 7\n",
      "first_layer_in_dim: 71\n",
      "recommended_latent_dim: 64\n",
      "\n",
      "Latent vector shape: torch.Size([100, 64])\n",
      "Categorical covariates shape: torch.Size([100, 1])\n",
      "Embedded shape: torch.Size([100, 7])\n",
      "Generator input shape: torch.Size([100, 71])\n",
      "First layer input dim: 71\n",
      "First layer weight shape: torch.Size([256, 71])\n",
      "\n",
      "Generating samples for dataset3\n",
      "Generator dimensions:\n",
      "embedding_dims: [7]\n",
      "total_embedding_dim: 7\n",
      "first_layer_in_dim: 71\n",
      "recommended_latent_dim: 64\n",
      "\n",
      "Latent vector shape: torch.Size([100, 64])\n",
      "Categorical covariates shape: torch.Size([100, 1])\n",
      "Embedded shape: torch.Size([100, 7])\n",
      "Generator input shape: torch.Size([100, 71])\n",
      "First layer input dim: 71\n",
      "First layer weight shape: torch.Size([256, 71])\n",
      "\n",
      "Generating samples for dataset4\n",
      "Generator dimensions:\n",
      "embedding_dims: [7]\n",
      "total_embedding_dim: 7\n",
      "first_layer_in_dim: 71\n",
      "recommended_latent_dim: 64\n",
      "\n",
      "Latent vector shape: torch.Size([100, 64])\n",
      "Categorical covariates shape: torch.Size([100, 1])\n",
      "Embedded shape: torch.Size([100, 7])\n",
      "Generator input shape: torch.Size([100, 71])\n",
      "First layer input dim: 71\n",
      "First layer weight shape: torch.Size([256, 71])\n",
      "\n",
      "Generating samples for dataset5\n",
      "Generator dimensions:\n",
      "embedding_dims: [7]\n",
      "total_embedding_dim: 7\n",
      "first_layer_in_dim: 71\n",
      "recommended_latent_dim: 64\n",
      "\n",
      "Latent vector shape: torch.Size([100, 64])\n",
      "Categorical covariates shape: torch.Size([100, 1])\n",
      "Embedded shape: torch.Size([100, 7])\n",
      "Generator input shape: torch.Size([100, 71])\n",
      "First layer input dim: 71\n",
      "First layer weight shape: torch.Size([256, 71])\n",
      "\n",
      "Generating samples for dataset6\n",
      "Generator dimensions:\n",
      "embedding_dims: [7]\n",
      "total_embedding_dim: 7\n",
      "first_layer_in_dim: 71\n",
      "recommended_latent_dim: 64\n",
      "\n",
      "Latent vector shape: torch.Size([100, 64])\n",
      "Categorical covariates shape: torch.Size([100, 1])\n",
      "Embedded shape: torch.Size([100, 7])\n",
      "Generator input shape: torch.Size([100, 71])\n",
      "First layer input dim: 71\n",
      "First layer weight shape: torch.Size([256, 71])\n",
      "\n",
      "Generating samples for dataset7\n",
      "Generator dimensions:\n",
      "embedding_dims: [7]\n",
      "total_embedding_dim: 7\n",
      "first_layer_in_dim: 71\n",
      "recommended_latent_dim: 64\n",
      "\n",
      "Latent vector shape: torch.Size([100, 64])\n",
      "Categorical covariates shape: torch.Size([100, 1])\n",
      "Embedded shape: torch.Size([100, 7])\n",
      "Generator input shape: torch.Size([100, 71])\n",
      "First layer input dim: 71\n",
      "First layer weight shape: torch.Size([256, 71])\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "\n",
    "# Set directories\n",
    "run_dir = \"/Users/guyshani/Documents/PHD/Aim_2/10x_data_mouse/saved_models/run_20250112_163225_dataset/\"\n",
    "generator_model = \"generator_20250112_163225_dataset.pt\"\n",
    "\n",
    "# Device configuration\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load configuration\n",
    "config_path = os.path.join(run_dir, 'model_config.json')\n",
    "with open(config_path, 'r') as f:\n",
    "    model_config = json.load(f)\n",
    "    \n",
    "# Initialize models with saved configuration\n",
    "generator = Generator(\n",
    "    x_dim=model_config['x_dim'],\n",
    "    vocab_sizes=model_config['vocab_sizes'],\n",
    "    nb_numeric=model_config['nb_numeric'],\n",
    "    h_dims=model_config['h_dims'],\n",
    "    z_dim=model_config['z_dim']).to(device)\n",
    "    \n",
    "discriminator = Discriminator(\n",
    "    x_dim=model_config['x_dim'],\n",
    "    vocab_sizes=model_config['vocab_sizes'],\n",
    "    nb_numeric=model_config['nb_numeric'],\n",
    "    h_dims=model_config['h_dims']).to(device)\n",
    "\n",
    "\n",
    "\n",
    "#discriminator_path = os.path.join(run_dir, \"discriminator.pt\")\n",
    "#discriminator.load_state_dict(torch.load(discriminator_path, map_location=device, weights_only=True))\n",
    "generator_path = os.path.join(run_dir, generator_model)\n",
    "generator.load_state_dict(torch.load(generator_path, map_location=device, weights_only=True))\n",
    "\n",
    "\n",
    "all_samples, categories = generate_and_save_profiles(\n",
    "    generator,\n",
    "    n_samples_per_category=100,\n",
    "    save_path=run_dir+'generated_data',\n",
    "    debug=True  # Enable debug output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41579</th>\n",
       "      <th>41580</th>\n",
       "      <th>41581</th>\n",
       "      <th>41582</th>\n",
       "      <th>41583</th>\n",
       "      <th>41584</th>\n",
       "      <th>41585</th>\n",
       "      <th>41586</th>\n",
       "      <th>41587</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.836664</td>\n",
       "      <td>-0.173137</td>\n",
       "      <td>-0.048852</td>\n",
       "      <td>-0.056615</td>\n",
       "      <td>-0.111151</td>\n",
       "      <td>-0.213191</td>\n",
       "      <td>0.098130</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>-0.082588</td>\n",
       "      <td>-0.193292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233236</td>\n",
       "      <td>0.857102</td>\n",
       "      <td>0.323777</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-0.270658</td>\n",
       "      <td>0.257891</td>\n",
       "      <td>-0.242051</td>\n",
       "      <td>-0.060632</td>\n",
       "      <td>dataset1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.420519</td>\n",
       "      <td>-0.878203</td>\n",
       "      <td>-0.016036</td>\n",
       "      <td>-0.649573</td>\n",
       "      <td>-0.898842</td>\n",
       "      <td>-0.709133</td>\n",
       "      <td>-0.478758</td>\n",
       "      <td>-0.900632</td>\n",
       "      <td>-0.554757</td>\n",
       "      <td>-0.784076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.859491</td>\n",
       "      <td>-1.149823</td>\n",
       "      <td>3.508285</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>-1.053828</td>\n",
       "      <td>-1.396616</td>\n",
       "      <td>4.058584</td>\n",
       "      <td>-1.391942</td>\n",
       "      <td>-1.613365</td>\n",
       "      <td>dataset1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257364</td>\n",
       "      <td>-0.410113</td>\n",
       "      <td>-0.168651</td>\n",
       "      <td>0.019554</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.025765</td>\n",
       "      <td>0.105883</td>\n",
       "      <td>0.720470</td>\n",
       "      <td>0.320675</td>\n",
       "      <td>-0.161310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339561</td>\n",
       "      <td>0.272903</td>\n",
       "      <td>0.032933</td>\n",
       "      <td>-0.193340</td>\n",
       "      <td>-0.125451</td>\n",
       "      <td>0.147760</td>\n",
       "      <td>-0.238648</td>\n",
       "      <td>-0.175982</td>\n",
       "      <td>0.486519</td>\n",
       "      <td>dataset1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.041994</td>\n",
       "      <td>-0.096628</td>\n",
       "      <td>0.107887</td>\n",
       "      <td>0.093147</td>\n",
       "      <td>-0.119546</td>\n",
       "      <td>-0.143102</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>-0.036449</td>\n",
       "      <td>-0.087694</td>\n",
       "      <td>-0.096305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187571</td>\n",
       "      <td>-0.296984</td>\n",
       "      <td>0.569445</td>\n",
       "      <td>0.141704</td>\n",
       "      <td>-0.155149</td>\n",
       "      <td>-0.222770</td>\n",
       "      <td>0.511674</td>\n",
       "      <td>-0.196746</td>\n",
       "      <td>-0.231371</td>\n",
       "      <td>dataset1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084030</td>\n",
       "      <td>0.034210</td>\n",
       "      <td>0.217438</td>\n",
       "      <td>0.271770</td>\n",
       "      <td>-0.120320</td>\n",
       "      <td>-0.120483</td>\n",
       "      <td>0.535898</td>\n",
       "      <td>0.032819</td>\n",
       "      <td>-0.073668</td>\n",
       "      <td>0.045240</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050118</td>\n",
       "      <td>-0.015386</td>\n",
       "      <td>0.251784</td>\n",
       "      <td>0.312822</td>\n",
       "      <td>0.039282</td>\n",
       "      <td>-0.125010</td>\n",
       "      <td>-0.082538</td>\n",
       "      <td>-0.085942</td>\n",
       "      <td>-0.000719</td>\n",
       "      <td>dataset1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.553130</td>\n",
       "      <td>-0.289484</td>\n",
       "      <td>-0.126051</td>\n",
       "      <td>-0.236413</td>\n",
       "      <td>-0.109200</td>\n",
       "      <td>-0.313937</td>\n",
       "      <td>-0.086129</td>\n",
       "      <td>-0.024629</td>\n",
       "      <td>-0.228695</td>\n",
       "      <td>-0.270952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474593</td>\n",
       "      <td>0.234379</td>\n",
       "      <td>0.966087</td>\n",
       "      <td>-0.131921</td>\n",
       "      <td>-0.516797</td>\n",
       "      <td>-0.442748</td>\n",
       "      <td>0.957596</td>\n",
       "      <td>-0.505236</td>\n",
       "      <td>-0.189231</td>\n",
       "      <td>dataset7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1.734083</td>\n",
       "      <td>-0.456024</td>\n",
       "      <td>-0.048328</td>\n",
       "      <td>0.227071</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>-0.609462</td>\n",
       "      <td>0.458538</td>\n",
       "      <td>0.750408</td>\n",
       "      <td>0.031424</td>\n",
       "      <td>-0.096684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763727</td>\n",
       "      <td>1.545573</td>\n",
       "      <td>0.839734</td>\n",
       "      <td>0.435531</td>\n",
       "      <td>-0.558352</td>\n",
       "      <td>-0.387740</td>\n",
       "      <td>0.165579</td>\n",
       "      <td>-0.834695</td>\n",
       "      <td>0.145693</td>\n",
       "      <td>dataset7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>1.221476</td>\n",
       "      <td>0.087605</td>\n",
       "      <td>0.694797</td>\n",
       "      <td>0.768075</td>\n",
       "      <td>-0.355958</td>\n",
       "      <td>-0.615676</td>\n",
       "      <td>1.176754</td>\n",
       "      <td>0.196508</td>\n",
       "      <td>-0.049763</td>\n",
       "      <td>0.150603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100679</td>\n",
       "      <td>1.442197</td>\n",
       "      <td>0.389280</td>\n",
       "      <td>1.605862</td>\n",
       "      <td>-0.531913</td>\n",
       "      <td>-0.458261</td>\n",
       "      <td>-0.405126</td>\n",
       "      <td>-0.386913</td>\n",
       "      <td>0.078110</td>\n",
       "      <td>dataset7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0.976643</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.027495</td>\n",
       "      <td>-0.162150</td>\n",
       "      <td>0.252294</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>-0.259395</td>\n",
       "      <td>0.436169</td>\n",
       "      <td>0.108348</td>\n",
       "      <td>-0.316288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410118</td>\n",
       "      <td>1.267244</td>\n",
       "      <td>0.025311</td>\n",
       "      <td>0.254876</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>0.170417</td>\n",
       "      <td>0.096193</td>\n",
       "      <td>-0.365324</td>\n",
       "      <td>0.285262</td>\n",
       "      <td>dataset7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>-0.155657</td>\n",
       "      <td>-0.074912</td>\n",
       "      <td>-0.332410</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>-0.017148</td>\n",
       "      <td>-0.034553</td>\n",
       "      <td>0.209291</td>\n",
       "      <td>-0.127332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166780</td>\n",
       "      <td>-0.337949</td>\n",
       "      <td>0.183134</td>\n",
       "      <td>-0.579375</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.220112</td>\n",
       "      <td>0.295758</td>\n",
       "      <td>-0.084687</td>\n",
       "      <td>dataset7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows  41589 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.836664 -0.173137 -0.048852 -0.056615 -0.111151 -0.213191  0.098130   \n",
       "1    0.420519 -0.878203 -0.016036 -0.649573 -0.898842 -0.709133 -0.478758   \n",
       "2    0.257364 -0.410113 -0.168651  0.019554  0.605600  0.025765  0.105883   \n",
       "3   -0.041994 -0.096628  0.107887  0.093147 -0.119546 -0.143102  0.205479   \n",
       "4    0.084030  0.034210  0.217438  0.271770 -0.120320 -0.120483  0.535898   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "695  0.553130 -0.289484 -0.126051 -0.236413 -0.109200 -0.313937 -0.086129   \n",
       "696  1.734083 -0.456024 -0.048328  0.227071  0.323782 -0.609462  0.458538   \n",
       "697  1.221476  0.087605  0.694797  0.768075 -0.355958 -0.615676  1.176754   \n",
       "698  0.976643 -0.489326  0.027495 -0.162150  0.252294  0.087300 -0.259395   \n",
       "699 -0.155657 -0.074912 -0.332410  0.007187  0.010113  0.234200 -0.017148   \n",
       "\n",
       "            7         8         9  ...     41579     41580     41581  \\\n",
       "0    0.008074 -0.082588 -0.193292  ... -0.233236  0.857102  0.323777   \n",
       "1   -0.900632 -0.554757 -0.784076  ... -0.859491 -1.149823  3.508285   \n",
       "2    0.720470  0.320675 -0.161310  ... -0.339561  0.272903  0.032933   \n",
       "3   -0.036449 -0.087694 -0.096305  ... -0.187571 -0.296984  0.569445   \n",
       "4    0.032819 -0.073668  0.045240  ... -0.050118 -0.015386  0.251784   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "695 -0.024629 -0.228695 -0.270952  ... -0.474593  0.234379  0.966087   \n",
       "696  0.750408  0.031424 -0.096684  ... -0.763727  1.545573  0.839734   \n",
       "697  0.196508 -0.049763  0.150603  ...  0.100679  1.442197  0.389280   \n",
       "698  0.436169  0.108348 -0.316288  ... -0.410118  1.267244  0.025311   \n",
       "699 -0.034553  0.209291 -0.127332  ... -0.166780 -0.337949  0.183134   \n",
       "\n",
       "        41582     41583     41584     41585     41586     41587   dataset  \n",
       "0    0.100324 -0.346655 -0.270658  0.257891 -0.242051 -0.060632  dataset1  \n",
       "1    0.040627 -1.053828 -1.396616  4.058584 -1.391942 -1.613365  dataset1  \n",
       "2   -0.193340 -0.125451  0.147760 -0.238648 -0.175982  0.486519  dataset1  \n",
       "3    0.141704 -0.155149 -0.222770  0.511674 -0.196746 -0.231371  dataset1  \n",
       "4    0.312822  0.039282 -0.125010 -0.082538 -0.085942 -0.000719  dataset1  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "695 -0.131921 -0.516797 -0.442748  0.957596 -0.505236 -0.189231  dataset7  \n",
       "696  0.435531 -0.558352 -0.387740  0.165579 -0.834695  0.145693  dataset7  \n",
       "697  1.605862 -0.531913 -0.458261 -0.405126 -0.386913  0.078110  dataset7  \n",
       "698  0.254876  0.016877  0.170417  0.096193 -0.365324  0.285262  dataset7  \n",
       "699 -0.579375  0.113691  0.027322  0.220112  0.295758 -0.084687  dataset7  \n",
       "\n",
       "[700 rows x 41589 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load generated data\n",
    "# Load the generated profiles\n",
    "profiles = np.load(run_dir + 'generated_data_profiles.npy')\n",
    "\n",
    "# Load categories\n",
    "with open(run_dir + 'generated_data_categories.txt', 'r') as f:\n",
    "    categories = [line.strip() for line in f]\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(profiles)\n",
    "\n",
    "# Add categories as a column\n",
    "df['dataset'] = categories\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
